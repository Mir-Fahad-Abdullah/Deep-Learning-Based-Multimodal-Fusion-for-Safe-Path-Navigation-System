{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb6a9129-1f8b-43b9-b0ba-bb0146656446",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cd9f7bf-8fe0-4ada-b92b-45b5ed754175",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import dataset_util\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a654377-39ff-4fbd-acee-08fa702adb79",
   "metadata": {},
   "source": [
    "# Directory paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01a3cee1-be2b-4f9e-85f9-abdcc999b091",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = r'C:\\Users\\ACER\\Jupyter_Notebook_Workplace\\Object-detection-dataset'\n",
    "train_dir = os.path.join(base_dir, 'train_combined')\n",
    "valid_dir = os.path.join(base_dir, 'valid')\n",
    "output_label_map_path = os.path.join(base_dir, 'label_map.pbtxt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2094c980-fee5-4935-930d-3d6cb188ab1a",
   "metadata": {},
   "source": [
    "# Extracting Label Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "214a19b4-1cb5-443d-914a-e94a1173abf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels used in your annotations:\n",
      "1: Tom Tom\n",
      "2: bench\n",
      "3: bin\n",
      "4: bus\n",
      "5: car\n",
      "6: chair\n",
      "7: cng\n",
      "8: dog\n",
      "9: door\n",
      "10: glass partition\n",
      "11: motorcycle\n",
      "12: person\n",
      "13: pillar\n",
      "14: railing\n",
      "15: rickshaw\n",
      "16: shelf\n",
      "17: stair\n",
      "18: table\n",
      "19: tempu\n",
      "20: tom tom\n",
      "21: tree\n",
      "22: truck\n",
      "23: umbrella\n",
      "24: van\n",
      "\n",
      "Label map saved to: C:\\Users\\ACER\\Jupyter_Notebook_Workplace\\Object-detection-dataset\\label_map.pbtxt\n"
     ]
    }
   ],
   "source": [
    "# Extract labels from XML files\n",
    "def extract_labels(directory):\n",
    "    labels = set()\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".xml\"):\n",
    "            tree = ET.parse(os.path.join(directory, filename))\n",
    "            root = tree.getroot()\n",
    "            for obj in root.findall('object'):\n",
    "                labels.add(obj.find('name').text.strip())\n",
    "    return labels\n",
    "\n",
    "# Extract and merge all labels\n",
    "train_labels = extract_labels(train_dir)\n",
    "valid_labels = extract_labels(valid_dir)\n",
    "all_labels = sorted(train_labels.union(valid_labels))\n",
    "\n",
    "# Create label_map dictionary\n",
    "label_map_dict = {i + 1: name for i, name in enumerate(all_labels)}\n",
    "\n",
    "# Print labels to console\n",
    "print(\"Labels used in your annotations:\")\n",
    "for idx, name in label_map_dict.items():\n",
    "    print(f\"{idx}: {name}\")\n",
    "\n",
    "# Save to label_map.pbtxt\n",
    "def save_label_map(label_map, filepath):\n",
    "    with open(filepath, 'w') as f:\n",
    "        for idx, name in label_map.items():\n",
    "            f.write(\"item {\\n\")\n",
    "            f.write(f\"  id: {idx}\\n\")\n",
    "            f.write(f\"  name: '{name}'\\n\")\n",
    "            f.write(\"}\\n\\n\")\n",
    "\n",
    "save_label_map(label_map_dict, output_label_map_path)\n",
    "\n",
    "print(f\"\\nLabel map saved to: {output_label_map_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56de8339-6f06-4f9d-9aa2-fa127a9e700b",
   "metadata": {},
   "source": [
    "# Convert Pascal VOC to TFRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5873527-6df8-43bd-b9c3-c4c340307c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label map saved to: C:\\Users\\ACER\\Jupyter_Notebook_Workplace\\Object-detection-dataset\\label_map.pbtxt\n",
      "TFRecord written to: C:\\Users\\ACER\\Jupyter_Notebook_Workplace\\Object-detection-dataset\\train.record\n",
      "TFRecord written to: C:\\Users\\ACER\\Jupyter_Notebook_Workplace\\Object-detection-dataset\\val.record\n"
     ]
    }
   ],
   "source": [
    "# Generate label map from XMLs\n",
    "def extract_labels(directory):\n",
    "    labels = set()\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".xml\"):\n",
    "            tree = ET.parse(os.path.join(directory, filename))\n",
    "            root = tree.getroot()\n",
    "            for obj in root.findall('object'):\n",
    "                labels.add(obj.find('name').text.strip())\n",
    "    return labels\n",
    "\n",
    "train_labels = extract_labels(train_dir)\n",
    "valid_labels = extract_labels(valid_dir)\n",
    "all_labels = sorted(train_labels.union(valid_labels))\n",
    "\n",
    "# Create label map dict: {label_name: id}\n",
    "label_map_dict = {name: i+1 for i, name in enumerate(all_labels)}\n",
    "\n",
    "# Save to label_map.pbtxt\n",
    "def save_label_map(label_map, filepath):\n",
    "    with open(filepath, 'w') as f:\n",
    "        for name, idx in label_map.items():\n",
    "            f.write(\"item {\\n\")\n",
    "            f.write(f\"  id: {idx}\\n\")\n",
    "            f.write(f\"  name: '{name}'\\n\")\n",
    "            f.write(\"}\\n\\n\")\n",
    "\n",
    "save_label_map(label_map_dict, output_label_map_path)\n",
    "print(f\"Label map saved to: {output_label_map_path}\")\n",
    "\n",
    "# Convert XML to TFRecord\n",
    "def create_tf_example(xml_path, label_map_dict):\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    image_path = xml_path.replace('.xml', '.jpg')\n",
    "    if not os.path.exists(image_path):\n",
    "        raise FileNotFoundError(f\"Image not found for {xml_path}\")\n",
    "\n",
    "\n",
    "    with tf.io.gfile.GFile(image_path, 'rb') as fid:\n",
    "        encoded_image_data = fid.read()\n",
    "\n",
    "    filename = os.path.basename(image_path).encode('utf8')\n",
    "    image_format = b'jpg'\n",
    "    width = int(root.find('size/width').text)\n",
    "    height = int(root.find('size/height').text)\n",
    "\n",
    "    xmins, xmaxs, ymins, ymaxs, classes_text, classes = [], [], [], [], [], []\n",
    "    for obj in root.findall('object'):\n",
    "        label = obj.find('name').text.strip()\n",
    "        classes_text.append(label.encode('utf8'))\n",
    "        classes.append(label_map_dict[label])\n",
    "        bbox = obj.find('bndbox')\n",
    "        xmins.append(float(bbox.find('xmin').text) / width)\n",
    "        xmaxs.append(float(bbox.find('xmax').text) / width)\n",
    "        ymins.append(float(bbox.find('ymin').text) / height)\n",
    "        ymaxs.append(float(bbox.find('ymax').text) / height)\n",
    "\n",
    "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image/height': dataset_util.int64_feature(height),\n",
    "        'image/width': dataset_util.int64_feature(width),\n",
    "        'image/filename': dataset_util.bytes_feature(filename),\n",
    "        'image/source_id': dataset_util.bytes_feature(filename),\n",
    "        'image/encoded': dataset_util.bytes_feature(encoded_image_data),\n",
    "        'image/format': dataset_util.bytes_feature(image_format),\n",
    "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "        'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "    }))\n",
    "    return tf_example\n",
    "\n",
    "def generate_tfrecord(output_path, image_dir, label_map_dict):\n",
    "    writer = tf.io.TFRecordWriter(output_path)\n",
    "    for filename in os.listdir(image_dir):\n",
    "        if filename.endswith('.xml'):\n",
    "            xml_path = os.path.join(image_dir, filename)\n",
    "            try:\n",
    "                tf_example = create_tf_example(xml_path, label_map_dict)\n",
    "                writer.write(tf_example.SerializeToString())\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping {xml_path} due to error: {e}\")\n",
    "    writer.close()\n",
    "    print(f\"TFRecord written to: {output_path}\")\n",
    "\n",
    "# Generate train.record and val.record\n",
    "generate_tfrecord(os.path.join(base_dir, 'train.record'), train_dir, label_map_dict)\n",
    "generate_tfrecord(os.path.join(base_dir, 'val.record'), valid_dir, label_map_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d1e7ca-282b-4e3a-8691-a7a6efe42a65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
